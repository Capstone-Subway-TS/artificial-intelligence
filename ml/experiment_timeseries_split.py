"""
ì‹œê³„ì—´ ë¶„í•  ì‹¤í—˜: ëœë¤ ë¶„í•  vs ì‹œê°„ìˆœ ë¶„í•  ë¹„êµ

ë¬¸ì œ: train_test_splitì€ ì‹œê³„ì—´ ë°ì´í„°ì— ë¶€ì í•©
- ë¯¸ë˜ ë°ì´í„°ë¡œ ê³¼ê±°ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë¬¸ì œ ë°œìƒ
- ì‹¤ì œ ì„±ëŠ¥ë³´ë‹¤ ê³¼ëŒ€í‰ê°€ë  ìˆ˜ ìˆìŒ

ì‹¤í—˜:
- ë°©ë²• 1: ëœë¤ ë¶„í•  (í˜„ì¬ ë°©ì‹, ë¬¸ì œ ìˆìŒ)
- ë°©ë²• 2: ì‹œê°„ìˆœ ë‹¨ìˆœ ë¶„í• 
- ë°©ë²• 3: ì‹œê³„ì—´ êµì°¨ê²€ì¦ (TimeSeriesSplit)
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, TimeSeriesSplit
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.preprocessing import LabelEncoder
import warnings
warnings.filterwarnings('ignore')


def load_and_prepare_data(path, sample_size=100000):
    """ë°ì´í„° ë¡œë“œ ë° ì¤€ë¹„"""
    print("=" * 60)
    print("Step 1: ë°ì´í„° ë¡œë“œ ë° ì¤€ë¹„")
    print("=" * 60)

    df = pd.read_csv(path)
    print(f"ì „ì²´ ë°ì´í„°: {len(df):,}ê±´")

    # datetime ì»¬ëŸ¼ ë³€í™˜
    df['datetime'] = pd.to_datetime(df['datetime'])

    # ì‹œê°„ìˆœ ì •ë ¬ (ì¤‘ìš”!)
    df = df.sort_values('datetime').reset_index(drop=True)
    print(f"ë°ì´í„° ê¸°ê°„: {df['datetime'].min()} ~ {df['datetime'].max()}")

    if sample_size and len(df) > sample_size:
        # ì‹œê³„ì—´ì´ë¯€ë¡œ ëœë¤ ìƒ˜í”Œë§ ëŒ€ì‹  ë’¤ìª½ ë°ì´í„° ì‚¬ìš©
        df = df.tail(sample_size).reset_index(drop=True)
        print(f"ìƒ˜í”Œë§ í›„: {len(df):,}ê±´")
        print(f"ìƒ˜í”Œ ê¸°ê°„: {df['datetime'].min()} ~ {df['datetime'].max()}")

    # í”¼ì²˜ ì¤€ë¹„
    le_station = LabelEncoder()
    le_prev = LabelEncoder()

    df['station_encoded'] = le_station.fit_transform(df['station'].astype(str))
    df['prev_station_encoded'] = le_prev.fit_transform(df['prev_station'].astype(str))

    # ì‹œê°„ ìˆœí™˜ ì¸ì½”ë”©
    df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)
    df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)
    df['dow_sin'] = np.sin(2 * np.pi * df['dayofweek'] / 7)
    df['dow_cos'] = np.cos(2 * np.pi * df['dayofweek'] / 7)

    # ëŒ€ì²´ í”¼ì²˜ (ë¬¸ì œ 1ì—ì„œ ë§Œë“  ê²ƒ)
    df['hist_avg_by_dow_hour'] = df.groupby(
        ['station', 'prev_station', 'dayofweek', 'hour']
    )['duration'].transform('mean')

    return df


def get_features_and_target(df):
    """í”¼ì²˜ì™€ íƒ€ê²Ÿ ë¶„ë¦¬ (ì„œë¹„ìŠ¤ ê°€ëŠ¥í•œ í”¼ì²˜ë§Œ ì‚¬ìš©)"""

    # ì„œë¹„ìŠ¤ ê°€ëŠ¥í•œ í”¼ì²˜ë§Œ! (lag í”¼ì²˜ ì œì™¸)
    features = [
        'hour', 'dayofweek', 'is_weekend', 'is_holiday',
        'is_morning_rush', 'is_evening_rush', 'is_rush_hour',
        'avg_duration', 'station_encoded', 'prev_station_encoded',
        'hour_sin', 'hour_cos', 'dow_sin', 'dow_cos',
        'hist_avg_by_dow_hour'  # ëŒ€ì²´ í”¼ì²˜
    ]

    features = [f for f in features if f in df.columns]
    target = 'delay'

    # ê²°ì¸¡ì¹˜ ì œê±°
    df_clean = df.dropna(subset=features + [target])

    return df_clean, features, target


def train_and_evaluate(X_train, X_test, y_train, y_test):
    """ëª¨ë¸ í•™ìŠµ ë° í‰ê°€"""
    model = GradientBoostingRegressor(
        n_estimators=100,
        max_depth=5,
        learning_rate=0.1,
        random_state=42
    )

    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    return {
        'mae': mean_absolute_error(y_test, y_pred),
        'rmse': np.sqrt(mean_squared_error(y_test, y_pred)),
        'r2': r2_score(y_test, y_pred)
    }


def experiment_random_split(df, features, target):
    """ë°©ë²• 1: ëœë¤ ë¶„í•  (í˜„ì¬ ë°©ì‹)"""
    print("\n" + "=" * 60)
    print("ë°©ë²• 1: ëœë¤ ë¶„í•  (í˜„ì¬ ë°©ì‹)")
    print("=" * 60)
    print("âš ï¸  ì‹œê³„ì—´ ë°ì´í„°ì— ë¶€ì í•©! (ë¹„êµìš©)")

    X = df[features]
    y = df[target]

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )

    print(f"í•™ìŠµ ë°ì´í„°: {len(X_train):,}ê±´")
    print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(X_test):,}ê±´")

    # ë¬¸ì œ ì‹œê°í™”: í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ ì‹œê°„ ë¶„í¬
    test_indices = X_test.index
    train_indices = X_train.index

    test_dates = df.loc[test_indices, 'datetime']
    train_dates = df.loc[train_indices, 'datetime']

    print(f"\ní•™ìŠµ ë°ì´í„° ê¸°ê°„: {train_dates.min()} ~ {train_dates.max()}")
    print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„° ê¸°ê°„: {test_dates.min()} ~ {test_dates.max()}")
    print("â†’ í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ í•™ìŠµ ë°ì´í„° ì‚¬ì´ì‚¬ì´ì— ì„ì—¬ìˆìŒ! âŒ")

    result = train_and_evaluate(X_train, X_test, y_train, y_test)

    print(f"\nğŸ“Š ê²°ê³¼:")
    print(f"   MAE:  {result['mae']:.2f}ì´ˆ")
    print(f"   RMSE: {result['rmse']:.2f}ì´ˆ")
    print(f"   RÂ²:   {result['r2']:.4f}")

    return result


def experiment_time_based_split(df, features, target):
    """ë°©ë²• 2: ì‹œê°„ìˆœ ë‹¨ìˆœ ë¶„í• """
    print("\n" + "=" * 60)
    print("ë°©ë²• 2: ì‹œê°„ìˆœ ë‹¨ìˆœ ë¶„í• ")
    print("=" * 60)
    print("âœ… ì˜¬ë°”ë¥¸ ë°©ë²•: ê³¼ê±°ë¡œ ë¯¸ë˜ ì˜ˆì¸¡")

    # ì´ë¯¸ ì‹œê°„ìˆœ ì •ë ¬ë˜ì–´ ìˆìŒ
    split_idx = int(len(df) * 0.8)

    train_df = df.iloc[:split_idx]
    test_df = df.iloc[split_idx:]

    X_train = train_df[features]
    y_train = train_df[target]
    X_test = test_df[features]
    y_test = test_df[target]

    print(f"í•™ìŠµ ë°ì´í„°: {len(X_train):,}ê±´")
    print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(X_test):,}ê±´")

    print(f"\ní•™ìŠµ ë°ì´í„° ê¸°ê°„: {train_df['datetime'].min()} ~ {train_df['datetime'].max()}")
    print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„° ê¸°ê°„: {test_df['datetime'].min()} ~ {test_df['datetime'].max()}")
    print("â†’ í•™ìŠµ(ê³¼ê±°) â†’ í…ŒìŠ¤íŠ¸(ë¯¸ë˜) ìˆœì„œ âœ…")

    result = train_and_evaluate(X_train, X_test, y_train, y_test)

    print(f"\nğŸ“Š ê²°ê³¼:")
    print(f"   MAE:  {result['mae']:.2f}ì´ˆ")
    print(f"   RMSE: {result['rmse']:.2f}ì´ˆ")
    print(f"   RÂ²:   {result['r2']:.4f}")

    return result


def experiment_timeseries_cv(df, features, target, n_splits=5):
    """ë°©ë²• 3: ì‹œê³„ì—´ êµì°¨ê²€ì¦"""
    print("\n" + "=" * 60)
    print(f"ë°©ë²• 3: ì‹œê³„ì—´ êµì°¨ê²€ì¦ ({n_splits} Folds)")
    print("=" * 60)
    print("âœ… ê°€ì¥ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë°©ë²•")

    X = df[features].values
    y = df[target].values

    tscv = TimeSeriesSplit(n_splits=n_splits)

    results = []

    print("\nê° Fold ê²°ê³¼:")
    print("-" * 50)

    for fold, (train_idx, test_idx) in enumerate(tscv.split(X), 1):
        X_train, X_test = X[train_idx], X[test_idx]
        y_train, y_test = y[train_idx], y[test_idx]

        # ê¸°ê°„ í™•ì¸
        train_start = df.iloc[train_idx[0]]['datetime']
        train_end = df.iloc[train_idx[-1]]['datetime']
        test_start = df.iloc[test_idx[0]]['datetime']
        test_end = df.iloc[test_idx[-1]]['datetime']

        result = train_and_evaluate(X_train, X_test, y_train, y_test)
        results.append(result)

        print(f"Fold {fold}: í•™ìŠµ({train_start.strftime('%m/%d')}~{train_end.strftime('%m/%d')}) â†’ "
              f"í…ŒìŠ¤íŠ¸({test_start.strftime('%m/%d')}~{test_end.strftime('%m/%d')}) | "
              f"MAE: {result['mae']:.2f}ì´ˆ")

    # í‰ê·  ê³„ì‚°
    avg_mae = np.mean([r['mae'] for r in results])
    avg_rmse = np.mean([r['rmse'] for r in results])
    avg_r2 = np.mean([r['r2'] for r in results])
    std_mae = np.std([r['mae'] for r in results])

    print("-" * 50)
    print(f"\nğŸ“Š í‰ê·  ê²°ê³¼:")
    print(f"   MAE:  {avg_mae:.2f}ì´ˆ (Â±{std_mae:.2f})")
    print(f"   RMSE: {avg_rmse:.2f}ì´ˆ")
    print(f"   RÂ²:   {avg_r2:.4f}")

    return {
        'mae': avg_mae,
        'rmse': avg_rmse,
        'r2': avg_r2,
        'std_mae': std_mae,
        'fold_results': results
    }


def run_experiment(data_path):
    """ì‹¤í—˜ ì‹¤í–‰"""

    # 1. ë°ì´í„° ì¤€ë¹„
    df = load_and_prepare_data(data_path, sample_size=100000)
    df_clean, features, target = get_features_and_target(df)

    print(f"\nì‚¬ìš© í”¼ì²˜: {len(features)}ê°œ")
    print(f"ìœ íš¨ ë°ì´í„°: {len(df_clean):,}ê±´")

    # 2. ì„¸ ê°€ì§€ ë°©ë²• ë¹„êµ
    result_random = experiment_random_split(df_clean, features, target)
    result_time = experiment_time_based_split(df_clean, features, target)
    result_cv = experiment_timeseries_cv(df_clean, features, target, n_splits=5)

    # 3. ìµœì¢… ë¹„êµ
    print("\n" + "=" * 60)
    print("ğŸ“Š ìµœì¢… ë¹„êµ ê²°ê³¼")
    print("=" * 60)

    print("""
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚      ë¶„í•  ë°©ë²•      â”‚   MAE   â”‚  RMSE   â”‚   RÂ²    â”‚ ì í•©ì„±   â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤""")
    print(f"    â”‚ 1. ëœë¤ ë¶„í•         â”‚ {result_random['mae']:>6.2f}ì´ˆ â”‚ {result_random['rmse']:>6.2f}ì´ˆ â”‚ {result_random['r2']:>6.4f} â”‚   âŒ     â”‚")
    print(f"    â”‚ 2. ì‹œê°„ìˆœ ë¶„í•       â”‚ {result_time['mae']:>6.2f}ì´ˆ â”‚ {result_time['rmse']:>6.2f}ì´ˆ â”‚ {result_time['r2']:>6.4f} â”‚   âœ…     â”‚")
    print(f"    â”‚ 3. ì‹œê³„ì—´ CV (í‰ê· ) â”‚ {result_cv['mae']:>6.2f}ì´ˆ â”‚ {result_cv['rmse']:>6.2f}ì´ˆ â”‚ {result_cv['r2']:>6.4f} â”‚   âœ…âœ…   â”‚")
    print("    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")

    # 4. ë¶„ì„
    print("\n" + "=" * 60)
    print("ğŸ’¡ ë¶„ì„")
    print("=" * 60)

    overestimate = result_time['mae'] - result_random['mae']

    if overestimate > 0:
        print(f"""
    âš ï¸  ëœë¤ ë¶„í• ì´ ì„±ëŠ¥ì„ ê³¼ëŒ€í‰ê°€í•˜ê³  ìˆì—ˆìŒ!

    - ëœë¤ ë¶„í•  MAE: {result_random['mae']:.2f}ì´ˆ
    - ì‹œê°„ìˆœ ë¶„í•  MAE: {result_time['mae']:.2f}ì´ˆ
    - ì°¨ì´: {overestimate:.2f}ì´ˆ ({overestimate/result_time['mae']*100:.1f}% ê³¼ëŒ€í‰ê°€)

    â†’ ì‹¤ì œ ì„œë¹„ìŠ¤ì—ì„œëŠ” ì‹œê°„ìˆœ ë¶„í•  ê¸°ì¤€ ì„±ëŠ¥({result_time['mae']:.2f}ì´ˆ)ì´ í˜„ì‹¤ì 
        """)
    else:
        print(f"""
    ëœë¤ ë¶„í• ê³¼ ì‹œê°„ìˆœ ë¶„í•  ì„±ëŠ¥ì´ ë¹„ìŠ·í•¨

    - ëœë¤ ë¶„í•  MAE: {result_random['mae']:.2f}ì´ˆ
    - ì‹œê°„ìˆœ ë¶„í•  MAE: {result_time['mae']:.2f}ì´ˆ

    â†’ ì´ ê²½ìš°ì—ë„ ì‹œê°„ìˆœ ë¶„í• ì´ ë” ì ì ˆí•œ í‰ê°€ ë°©ë²•
        """)

    print(f"""
    ğŸ“Œ ê¶Œì¥ì‚¬í•­:
    1. ëª¨ë¸ í‰ê°€ ì‹œ ì‹œê³„ì—´ êµì°¨ê²€ì¦(TimeSeriesSplit) ì‚¬ìš©
    2. ìµœì¢… ì„±ëŠ¥ì€ {result_cv['mae']:.2f}ì´ˆ (Â±{result_cv['std_mae']:.2f})ë¡œ ë³´ê³ 
    3. ë©´ì ‘ì—ì„œ "ì‹œê³„ì—´ ë°ì´í„° íŠ¹ì„±ì„ ê³ ë ¤í–ˆë‹¤"ê³  ì„¤ëª…
    """)

    return {
        'random': result_random,
        'time_based': result_time,
        'timeseries_cv': result_cv
    }


if __name__ == '__main__':
    import sys

    data_path = sys.argv[1] if len(sys.argv) > 1 else 'data/processed_subway_data.csv'
    results = run_experiment(data_path)
